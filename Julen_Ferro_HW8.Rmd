---
title: "CS 422"
author: "Julen Ferro Ba√±ales. Master's in CDS&OR, Illinois Institute of Technology"
output:
  pdf_document:
    toc: yes
  html_notebook:
    toc: yes
    toc_float: yes
  html_document:
    toc: yes
    df_print: paged
---

<!-- More information in R Markdown can be found at:
1. https://www.ssc.wisc.edu/sscc/pubs/RFR/RFR_RMarkdown.html  This is 
   the place to start since it is a short tutorial.
2. https://rmarkdown.rstudio.com/index.html This contains a longer 
   tutorial.  Take a look at the cheatsheet in 
   https://rmarkdown.rstudio.com/lesson-15.html, it is a concise 
   reference of R Markdown on two pages.
<-->

## Use this as a template for your homeworks.
#### Rename it to firstname-lastname.Rmd.
#### Run all the chunks by clicking on "Run" at the top right of the edit 
#### window and choose "Run All".  Assuming there were no errors in the
#### chunk, you should see a "Preview" button become visible on the top
#### left of the edit window.  Click this button and a html document should
#### pop up with the output from this R markdown script.

### Part 2.1.
(a) Data cleanup (0.5 points)

Importing required modules.

```{r}

library(factoextra)
library(dplyr)
library(NbClust)
library(ggplot2)
library(ggpubr)
library(dbscan)


```



### Part 2.1-A-i

i) 

After having taken a look at the data set, it has been concluded that the numerical information will not the dropped. That is to say, the majority of the columns are filled with numerical information and would be used for the analysis, even though some of the columns' data could not be correlated with the results that it is wanted, or some columns' data could be a linear combination of others, as there will no be any statistical screening concerning the influence of each attribute, it cannot be concluded that deleting any of the numerical values will not lead to an information lose. About the first column, in which the names of the subject samples appers, this data is not really important for the data analysis, so it could be deleted. 

ii) 

Of course, the data should be standardized. Even though in the case of the different columns having numerical values of more or less the same order, it is always a good practice trying to standardize the numerical data. In this case, it should be standardized in order to calculate the clustering distances with whichever method is used (euclidean distance, Manhattan...) due to the fact that some rows reach a values ranging from 0 to 4, and other oens do not overpass values greater than one. 

iii) 


```{r}

set.seed(123) # setting a seed for the pseudo-random numbers
rm(list=ls())
dataframe <- read.csv(file = "file19.txt",     # TXT data file indicated as string or full path to the file
           header = TRUE,    # Whether to display the header (TRUE) or not (FALSE)
           sep = "",          # Separator of the columns of the file
           dec = ".",
           skip = 20,
           strip.white = TRUE,
           skipNul = TRUE)         # Character used to separate decimals of the numbers in the file

head(df, 8) # df before getting rid of the names
df = dataframe[, 2:ncol(dataframe)] # getting rid of the names in the df
head(df, 8) # df after getting rid of the names
plot(df, main="Raw points")

write.csv(df, "cleaned_file19.txt", row.names = FALSE, sep = ",")

df <- scale(df)




```
### Part 2.1.b)

i) 

```{r}
#Getting the optimal number of clusters

fviz_nbclust(df, kmeans, method = "wss") +
geom_vline(xintercept = 8, linetype = 2)
kopt = 8

```
The total OPTIMAL number of needed clusters is eight, as it happens to be the one that leads to the lowest SSE residual value. But any clustering close to eight cluster could be fine, as it would have a similar minimum SSE value. For instance, seven or nine. 

ii) 

```{r}

# Running K-means

k <- kmeans(df, centers= kopt)
#print(k) # see the result data of the clusters
fviz_cluster(k, data = df)


```

iii) 

```{r}

for (j in 1:kopt){
 print(paste0("In the ", j, " cluster, there are: ", k$size[j], " observations" ))
}



```

iv) 

```{r}

print(paste0(round(k$tot.withinss, 2), " is the total SSE value of the clusters"))


```

v) 

```{r}
for (i in 1:kopt){
  print(paste0("The SSE of the cluster number ", i , " is ", round(k$withinss[i], 2)))
}


```

vi) 

```{r}

for (i in 1:kopt){
  
  print(dataframe[which(k$cluster == i),])
  
}


```


### Part 2.2.a)


```{r}



```

### Part 2.1.b)

i) 

```{r}



```

ii) 

```{r}



```

### Part 2.1.c)

i) 

```{r}



```

ii) 

```{r}



```

iii) 

```{r}



```

### Part 2.1.d)

i) 

```{r}



```

ii) 

```{r}



```

iii) 

```{r}



```

### Part 2.1.e)

i) 

```{r}



```

ii) 

```{r}



```

### FINAL